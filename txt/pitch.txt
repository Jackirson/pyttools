1. 
Работа посвящена исп. субъективных суждений для принятия решений. Решения в данном случае принимаются по поводу выбора объектов. Есть ответственный за выбор -- лицо, принимающее решение.

2.
Объекты могут быть всякие, главное -- их n штук, и у каждого -- m одинаковых независимых параметров. Параметры числовые (например, по вот такой десятибалльной шкале), но их значения неизвестны. Эта неизвестность моделируется неопред. элементами.

Приходят эксперты. Они высказывают суждения по поводу значений параметров в виде распределений неопред. элементов. Это и есть экспертные оценки. Каждый эксперт оценивает все параметры всех объектов. Считаем, что конкретный эксперт работает в одной и той же шкале правдоподоб. Разные эксперты -- в разных шкалах.
В программном комплексе экспертные оценки изображаются вот так вот.

3.
Надо выбрать наиболее качественные объекты, поэтому вводится модель качества -- функция f. Она задается лицом, принимающем решение, и должна быть монотонна по каждому аргументу. Например, для двух парметров можно взять их среднее арифметическое.
Общая схема работы программного комплеса такая: экспертные оценки подаются, если экспертов несколько, в алгоритм коллективной экспертизы. Потом уже это коллективное мнение (или один набор экспертных оценок, если эксперт работает один) подаётся, вместе с моделью качества объектов, в алгоритм выбора. 

4.
Итак, задача выбора. 
Выбор -- это некое подмн-во мн-ва всех объектов заданного размера k. А верный выбор при известных значениях параметров (если бы мы их знали) -- это подмножество строго наилучших объектов, того же размера k. 

Экспертные оценки порождают меру правдободобия и пространство с ней. Элементарным событием, кстати, там является как раз вектор "t" значений всех параметров всех объектов, всего таких векторов (число баллов у параметра)^(nm), например 10^(nm). 
Задача выбора ставится как задача на минимум правдоподобия ошибки, т.е. такого события, когда сделанный выбор не совпадает с верным выбором. 
Она может иметь не единственное решение. Часто в нашей практике получалось так, однозначно выбрать k объектов что можно не при всех k, поэтому их не всегда можно однозначно отранжировать.  

5. 
Правдоподобие события надо уметь вычислять. Если делать перебор всех 10^(nm) элементарных событий, это займет время O(10^(nm)). Но есть такая хитроть. 
Возьмём какое-то событие А, его возможность расписывается стандартным образом. И возьмём событие B следующего вида: это такие вектора "t" у которых все координаты имеют правдоподобие больше некоторого заданного уровня p0. Если и только если A и B пересекаются, то правдоподобие события A больше этого уровня p0. Причём алгоритм проверки этого работает за время O(nm). Таким и находится правдоподобие ошибки. 

6. 
Теперь переходим к задаче коллективной экспертизы, т.е. нахождения коллективного мнения экспертов. Тут есть несколько методов. Во-первых, это классические методы Юрия Петровича через матрицы парных сравнений или векторы перестановок. Для матриц парных сравнений постановка задача выписана ниже на этом слайде. Матрица  строится на основе уже совместного распределения, не маргинального, которые эксперты задают, а совместного (pl с одним только верхним номером эксперта). Во-вторых, есть новые методы: метод векторов предпочтений, и метод введения отношения предпорядка на множестве распределений правдоподобия одного и того же неопред. элемента. 

7. 
Векторы предпочтений. Задача ставится так же, как и для матриц парных сравнений, с использованием той же евклидовой метрики. Сам вектор предпочтений имеет столько же координат, сколько есть элементарных событий. Их, как вы помните, может быть довольно много. 
Каждая координата вектора предпочтений -- это количество элементарных событий, правдоподобие которых не больше правдоподобия события, которое соответствует этой координате. Вектор должен удовлетворять такому вот хитрому условию: количество координат со значением от единицы до i должно быть строго равно i.

8.
 Предпорядок. Это частичный порядок с точностью  до  возможной эквивалентности двух распределений. Тут написано определение. Оно включает в себя требование вложенности носителя и дополнительные требования, чтобы это было действительно отношением предпорядка. 
 Дальше, есть такая теорема: при некоторых достаточно общих условиях, задача выбора (та самая задача на минимум правдоподобия ошибки, да?..) ..множество оптимальных решений задачи выбора, полученное с использованием более узких оценок p(1), лежит внутри множества решений, полученного с помощью более широкой оценки. Т.е. действительно происходит некое уточнение информации, откуда сам термин, что одно правдоподобие "уточняет" другое.
 Ну а справа изображена полурешётка распределений, которая получается из этого отношения предпорядка. Видно, что "широкие" распределения уточняются дельтообразными, а тривиальное распределение уточняется всеми остальными. 
 
 9.
 Всё это хорошо, но во всех рассмотренных случаях опять возникла эта проблема с совместными распределениями, в которых так много элементарных событий, что с ними невозможно работать. 
 Но с предпорядком, видимо, есть выход. В силу теоремы не предыдущем слайде, в качестве коллективной экспертизы разумно использовать супремум двух распределений с точки зрения вот этого отношения предпорядка. Разработан новый алгоритм, который умеет считать супремум двух распределений, но только с небольшим количеством элементарных событий. Как быть? Попробуем найти не супремум, а другую верхнюю грань. Она будет уточняться супремумом и ближе к тривиальному распределению, но, возможно, будет выглядеть разумно. Для этого сделаем следующее. 
 (1) Вместо функции совместного распределения введём специальную  эвристическую функцию v. Мы как бы взяли одномерные распределения, которые эксперты задают, и "склеили" отдельно для каждого эксперта распределения для всех объектов по всем параметрам. 
(2) Получилось R как бы "длинных" одномерных функций, формально -- тоже распределений правдоподобия. Мы их можем прогнать через алгоритм нахождения супремума, получится одна такая "длинная" функция.
(3) Её мы разрезаем снова на куски по количеству баллов у одного параметра одного объекта, и получаем коллективное мнение экспертов по каждому параметру каждого объекта отдельно. 
То, что так можно делать, пока строго не доказано, но проверено на некоторых примерах.

10. 
Теперь результаты. 